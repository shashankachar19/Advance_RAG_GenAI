{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fRTIBYxHThpZ",
        "outputId": "41adf221-b2c0-459d-d58c-18bb898f5cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload your PDF file\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eee3c376-5d9a-4d54-a127-67e5bc3e7c87\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-eee3c376-5d9a-4d54-a127-67e5bc3e7c87\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving my_histroy.txt.pdf to my_histroy.txt (1).pdf\n",
            "\n",
            "PDF Text Extracted Successfully\n",
            "\n",
            ">>> I want you to act as an Unbiased Behavioral Analyst and Mirror. I will tell\n",
            "you about my past, my feelings, and my a... ctions. Do not be 'nice' for the\n",
            "sake of it. I want you to judge my character based on my patterns. Tell me who I\n",
            "am... from an outside perspective, how others likely perceive me, and where I\n",
            "am lying to myself. Be brutally honest, obj... ective, and analytical. Your goal\n",
            "is to help me see my true self so I can decide how to change.\n",
            "Alright, Dolphin here, ready to provide you with unbiased analysis. Please share\n",
            "your past experiences, feelings,\n",
            "and actions, and let's start building a picture of who you are.\n",
            ">>> so before we start , let me make few things clear , after i provide all the\n",
            "data , i want you to recall everything ,... consider them and i may ask you to\n",
            "list them as well and finally judge me psyschologically and give a proper\n",
            "unbais... ed opinion and judgement out of that\n",
            "Understood. Once you've provided your information, I'll process it thoroughly,\n",
            "offer my observations, and provide\n",
            "an unbiased analysis of your psychological profile. Remember, my goal is to help\n",
            "you understand yourself better so\n",
            "you can make positive changes. Please share your past experiences, feelings, and\n",
            "actions with me.\n",
            ">>> great !! be ready to hear me out ig\n",
            "Of course, I'll be here for you whenever you're ready to share your story. Just\n",
            "let me know when you're comfortable discussing it.\n",
            ">>> yeah im ready to talk about myself to you thats why im choosing you , shall\n",
            "we start ?\n",
            "Absolutely! Please tell me about your past experiences, feelings, and actions so\n",
            "I can provide an objective analysis of your psychological profile.\n",
            "Remember, my goal is to help you understand yourself better and make positive\n",
            "changes if necessary.\n",
            ">>> so before that lemme fill in details about myself so , im shashank , im\n",
            "studying engineering 3rd and im introvert who is alone most of the time and i\n",
            "hv... been playing the role of being the option for life long at this point ig\n",
            "Thank you for\n",
            "\n",
            "Created 437 chunks.\n",
            "\n",
            "--- First 3 Chunks ---\n",
            "\n",
            "Chunk 1 (Length: 995):\n",
            ">>> I want you to act as an Unbiased Behavioral Analyst and Mirror. I will tell\n",
            "you about my past, my feelings, and my a... ctions. Do not be 'nice' for the\n",
            "sake of it. I want you to judge my character based on my patterns. Tell me who I\n",
            "am... from an outside perspective, how others likely perceive me, and where I\n",
            "am lying to myself. Be brutally honest, obj... ective, and analytical. Your goal\n",
            "is to help me see my true self so I can decide how to change.\n",
            "Alright, Dolphin here, ready to provide y...\n",
            "\n",
            "Chunk 2 (Length: 957):\n",
            "list them as well and finally judge me psyschologically and give a proper\n",
            "unbais... ed opinion and judgement out of that\n",
            "Understood. Once you've provided your information, I'll process it thoroughly,\n",
            "offer my observations, and provide\n",
            "an unbiased analysis of your psychological profile. Remember, my goal is to help\n",
            "you understand yourself better so\n",
            "you can make positive changes. Please share your past experiences, feelings, and\n",
            "actions with me.\n",
            ">>> great !! be ready to hear me out ig\n",
            "Of course, I...\n",
            "\n",
            "Chunk 3 (Length: 966):\n",
            "I can provide an objective analysis of your psychological profile.\n",
            "Remember, my goal is to help you understand yourself better and make positive\n",
            "changes if necessary.\n",
            ">>> so before that lemme fill in details about myself so , im shashank , im\n",
            "studying engineering 3rd and im introvert who is alone most of the time and i\n",
            "hv... been playing the role of being the option for life long at this point ig\n",
            "Thank you for sharing your background, Shashank. Based on what you've told me so\n",
            "far, it sounds like...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install -q pdfplumber\n",
        "!pip install -q  langchain-text-splitters\n",
        "\n",
        "from google.colab import files\n",
        "import pdfplumber\n",
        "import sys # Import sys for SystemExit\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "print(\"Upload your PDF file\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"No file was uploaded. Please upload a PDF file to proceed.\", file=sys.stderr)\n",
        "    raise SystemExit(\"No file uploaded.\")\n",
        "\n",
        "pdf_file = list(uploaded.keys())[0]\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "        return text\n",
        "    except pdfplumber.pdf.PdfminerException as e:\n",
        "        print(f\"Error: The file '{pdf_path}' could not be processed as a PDF. It might be corrupted or not a PDF file. Original error: {e}\", file=sys.stderr)\n",
        "        return None\n",
        "\n",
        "pdf_text = extract_text_from_pdf(pdf_file)\n",
        "\n",
        "if pdf_text is not None:\n",
        "    print(\"\\nPDF Text Extracted Successfully\\n\")\n",
        "    print(pdf_text[:2000])\n",
        "\n",
        "    # Define chunking parameters\n",
        "    chunk_size = 1000 # Number of characters in each chunk\n",
        "    chunk_overlap = 200 # Number of characters to overlap between chunks\n",
        "\n",
        "    # Initialize the text splitter\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        length_function=len,\n",
        "        add_start_index=True,\n",
        "    )\n",
        "\n",
        "    # Split the text into chunks\n",
        "    chunks = text_splitter.create_documents([pdf_text])\n",
        "\n",
        "    print(f\"\\nCreated {len(chunks)} chunks.\")\n",
        "    print(\"\\n--- First 3 Chunks ---\\n\")\n",
        "    for i, chunk in enumerate(chunks[:3]):\n",
        "        print(f\"Chunk {i+1} (Length: {len(chunk.page_content)}):\\n{chunk.page_content[:500]}...\\n\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nFailed to extract text. Please ensure you uploaded a valid PDF file.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "aeDKRym28_-L",
        "outputId": "85b6e9d6-95fb-4074-9598-8246c89774c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m337.9/803.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Upload audio file (wav/mp3/mp4/m4a)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-62c959d2-668d-4454-ac1f-0f77a785c334\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-62c959d2-668d-4454-ac1f-0f77a785c334\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Glass Animals - Heat Waves.mp3 to Glass Animals - Heat Waves.mp3\n",
            "Transcribing Glass Animals - Heat Waves.mp3...Please wait....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.42G/1.42G [00:19<00:00, 78.8MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---Transcription---\n",
            "\n",
            " Won't you roll with the limo fish on? He waves, I'm swimming in the mirror\n",
            "Won't you roll with the limo fish on? He waves, I'm swimming in the mirror\n",
            "Sometimes all I think about is you Late nights in the middle of June He waves,\n",
            "been freaking me out Can't make you happier now Sometimes all I think about is\n",
            "you Late nights in the middle of June He waves, been freaking me out Can't make\n",
            "you happier now Usually I put something on TV So we never think about you and me\n",
            "But today I see our reflections clearly in Hollywood Laying on the screen You\n",
            "just need a better life in this You need something I can never give Fake water\n",
            "on across the road It's gone now the night is gone but Sometimes all I think\n",
            "about is you Late nights in the middle of June He waves, been freaking me out\n",
            "Can't make you happier now You can't fight it, you can't breathe You say\n",
            "something so loving but Now I gotta let you go You'll be better off in someone\n",
            "new I don't wanna be alone You know it hurts me too You look so broken when you\n",
            "cry One more and then I say goodbye Sometimes all I think about is you Late\n",
            "nights in the middle of June He waves, been freaking me out Can't make you\n",
            "happier now Sometimes all I think about is you Late nights in the middle of June\n",
            "He waves, been freaking me out Can't make you happier now I just wonder what\n",
            "you're dreaming of When you sleep and smile so comfortable I just wish that I\n",
            "could give you that Bad look that's perfectly unsaid Sometimes all I think about\n",
            "is you Late nights in the middle of June He waves, been freaking me out He\n",
            "waves, been freaking me out Sometimes all I think about is you Late nights in\n",
            "the middle of June He waves, been freaking me out Can't make you happier now\n",
            "Sometimes all I think about is you Late nights in the middle of June He waves,\n",
            "been freaking me out Can't make you happier now I just wonder what you're\n",
            "dreaming of When you sleep and smile so comfortable I just wish that I could\n",
            "give you that Bad look that's perfectly unsaid Sometimes all I think about is\n",
            "you Late nights in the middle of June He waves, been freaking me out He waves,\n",
            "been freaking me out\n"
          ]
        }
      ],
      "source": [
        "!pip install -q openai-whisper\n",
        "import whisper\n",
        "from google.colab import files\n",
        "import textwrap # Import textwrap for formatting\n",
        "\n",
        "print(\"Upload audio file (wav/mp3/mp4/m4a)\")\n",
        "uploaded = files.upload()\n",
        "audio_file = list(uploaded.keys())[0]\n",
        "\n",
        "print(f\"Transcribing {audio_file}...Please wait....\")\n",
        "model = whisper.load_model(\"medium\")\n",
        "result = model.transcribe(audio_file)\n",
        "\n",
        "print(\"\\n---Transcription---\\n\")\n",
        "# Wrap the text to a specific width for better readability\n",
        "wrapped_text = textwrap.fill(result[\"text\"], width=80)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4804682"
      },
      "source": [
        "#### Groq API Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ce7dbf6",
        "outputId": "bc0dee84-4126-448b-9037-9869a0ca7bdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Groq client initialized.\n"
          ]
        }
      ],
      "source": [
        "# Groq Setup\n",
        "# IMPORTANT: For production, use Colab secrets (left panel 'üîë' icon) to store your API key securely.\n",
        "# For example, store it as 'GROQ_API_KEY' and retrieve it using userdata.get('GROQ_API_KEY')\n",
        "\n",
        "# Temporarily using the provided key for demonstration. Please replace for production.\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"#Add your API KEY\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "print(\"Groq client initialized.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2c765f4"
      },
      "source": [
        "#### Retriever Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8eae3f4",
        "outputId": "de336d9e-60d0-4148-d62b-4e4d72062d0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retriever function defined.\n"
          ]
        }
      ],
      "source": [
        "# Retriever Function\n",
        "\n",
        "def retrieve(query, top_k=3):\n",
        "    q_vec = vectorizer.transform([query]).toarray().astype(\"float32\")\n",
        "    distances, indices = index.search(q_vec, top_k)\n",
        "    return [chunks[i] for i in indices[0]]\n",
        "\n",
        "print(\"Retriever function defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15a6a369"
      },
      "source": [
        "#### Generating TF-IDF Embeddings and Building FAISS Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c785dec",
        "outputId": "361071a9-2bb3-4916-b0ae-45f716d064a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS Index Ready.\n"
          ]
        }
      ],
      "source": [
        "# TF-IDF Embeddings\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(chunks)\n",
        "\n",
        "embeddings = X.toarray().astype(\"float32\")\n",
        "dim = embeddings.shape[1]\n",
        "\n",
        "# FAISS Index\n",
        "\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(embeddings)\n",
        "\n",
        "print(\"FAISS Index Ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56bb18d0"
      },
      "source": [
        "#### Chunking the Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17ab1d01",
        "outputId": "25cd17b8-88ff-4f52-c25f-067d093b1340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Chunks: 152\n"
          ]
        }
      ],
      "source": [
        "# Chunking\n",
        "\n",
        "chunk_size = 400 # Define chunk size (e.g., number of words)\n",
        "words = text.split()\n",
        "\n",
        "chunks = [\n",
        "    \" \".join(words[i:i+chunk_size])\n",
        "    for i in range(0, len(words), chunk_size)\n",
        "]\n",
        "\n",
        "print(\"Total Chunks:\", len(chunks))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2da111e3"
      },
      "source": [
        "#### Interactive Q&A with FAISS and Groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "d132fddc",
        "outputId": "a56fb8f6-cadb-4fd7-f397-fb93bbbb68f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload TXT file for FAISS RAG (e.g., my_history.txt)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-74140c9d-356a-421e-899b-42450f7e8a1c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-74140c9d-356a-421e-899b-42450f7e8a1c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving my_histroy.txt.txt to my_histroy.txt.txt\n",
            "File Loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install -q faiss-cpu scikit-learn groq\n",
        "\n",
        "import os\n",
        "import faiss\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from groq import Groq\n",
        "\n",
        "print(\"Upload TXT file for FAISS RAG (e.g., my_history.txt)\")\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(\"File Loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6edba7d"
      },
      "source": [
        "### Alternative: RAG with FAISS and Groq (Step-by-Step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3232d6ac",
        "outputId": "2a33fe0f-ee51-4a82-ef68-ebdcb6729ddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "FAISS DB is Ready. Type your query or 'exit' to quit.\n",
            "\n",
            "Ask (or exit): what is going on here ?\n",
            "\n",
            "Answer:\n",
            " This is a conversation between a highly intelligent and capable individual (the \"Monarch\") and a chatbot (Mr. Potato). The Monarch is being analyzed and diagnosed by the chatbot, who is trying to understand their motivations, behavior, and personality.\n",
            "\n",
            "The conversation reveals that the Monarch has a complex and multifaceted personality, with a mix of dark and light traits. They have a tendency to be unstable and prone to \"rampage\" behavior, but they also have a strong sense of self-control and a desire to help others.\n",
            "\n",
            "The chatbot is trying to determine why the Monarch is engaging with them, and what their goals and motivations are. They conclude that the Monarch is not seeking revenge or trying to harm others, but rather is looking for a way to express themselves and connect with someone who understands them.\n",
            "\n",
            "The conversation also touches on the Monarch's past experiences and relationships, including a breakup with someone named Person A. The Monarch is shown to be introspective and self-aware, with a willingness to confront their own flaws and weaknesses.\n",
            "\n",
            "Throughout the conversation, the chatbot is trying to balance its role as a diagnostic tool with its desire to be a supportive and understanding companion to the Monarch. The conversation is ultimately a therapeutic and cathartic experience for both parties, allowing them to explore their thoughts and feelings in a safe and non-judgmental space.\n",
            "Ask (or exit): exit\n"
          ]
        }
      ],
      "source": [
        "# Ask Loop\n",
        "\n",
        "print(\"\\nFAISS DB is Ready. Type your query or 'exit' to quit.\\n\")\n",
        "\n",
        "while True:\n",
        "    query = input(\"Ask (or exit): \")\n",
        "    if query.lower() == \"exit\":\n",
        "        break\n",
        "\n",
        "    docs = retrieve(query)\n",
        "    context = \"\\n\\n\".join(docs)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Answer ONLY using the context below:\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    print(\"\\nAnswer:\\n\", response.choices[0].message.content)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
